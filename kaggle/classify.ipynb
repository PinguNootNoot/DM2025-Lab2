{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89c6045e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e9c32f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x61fc95</td>\n",
       "      <td>We got the ranch, loaded our guns and sat up t...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x35663e</td>\n",
       "      <td>I bet there is an army of married couples who ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0xc78afe</td>\n",
       "      <td>This could only end badly.</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x90089c</td>\n",
       "      <td>My sister squeezed a lime in her milk when she...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0xaba820</td>\n",
       "      <td>and that got my head bobbing a little bit.</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64166</th>\n",
       "      <td>0x4afbe1</td>\n",
       "      <td>Guilty Gear actually did that before with Guil...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64167</th>\n",
       "      <td>0xf5ba78</td>\n",
       "      <td>One of my favorite episodes.</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64168</th>\n",
       "      <td>0x8f758e</td>\n",
       "      <td>I got my first raspberry from a crowd surfer f...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64169</th>\n",
       "      <td>0xb5a35a</td>\n",
       "      <td>Texans and Astros both shut out tonight. Houst...</td>\n",
       "      <td>[texans, astros, sadness, losers]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64170</th>\n",
       "      <td>0x3a9174</td>\n",
       "      <td>Pre-prepare direction plays hale and hearty si...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64171 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        post_id                                               text  \\\n",
       "0      0x61fc95  We got the ranch, loaded our guns and sat up t...   \n",
       "1      0x35663e  I bet there is an army of married couples who ...   \n",
       "2      0xc78afe                         This could only end badly.   \n",
       "3      0x90089c  My sister squeezed a lime in her milk when she...   \n",
       "4      0xaba820         and that got my head bobbing a little bit.   \n",
       "...         ...                                                ...   \n",
       "64166  0x4afbe1  Guilty Gear actually did that before with Guil...   \n",
       "64167  0xf5ba78                       One of my favorite episodes.   \n",
       "64168  0x8f758e  I got my first raspberry from a crowd surfer f...   \n",
       "64169  0xb5a35a  Texans and Astros both shut out tonight. Houst...   \n",
       "64170  0x3a9174  Pre-prepare direction plays hale and hearty si...   \n",
       "\n",
       "                                hashtags  \n",
       "0                                     []  \n",
       "1                                     []  \n",
       "2                                     []  \n",
       "3                                     []  \n",
       "4                                     []  \n",
       "...                                  ...  \n",
       "64166                                 []  \n",
       "64167                                 []  \n",
       "64168                                 []  \n",
       "64169  [texans, astros, sadness, losers]  \n",
       "64170                                 []  \n",
       "\n",
       "[64171 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = './data/final_posts.json'\n",
    "\n",
    "with open(path, 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "item_to_flatten = [record['root']['_source']['post'] for record in data]\n",
    "main_df = pd.json_normalize(item_to_flatten)\n",
    "main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adde5205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x35663e</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0xc78afe</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x90089c</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x2ffb63</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x989146</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    post_id emotion\n",
       "0  0x35663e     joy\n",
       "1  0xc78afe    fear\n",
       "2  0x90089c     joy\n",
       "3  0x2ffb63     joy\n",
       "4  0x989146     joy"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_emo = pd.read_csv('./data/emotion.csv')\n",
    "df_split = pd.read_csv('./data/data_identification.csv')\n",
    "\n",
    "df_emo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdc89d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>emotion</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x61fc95</td>\n",
       "      <td>We got the ranch, loaded our guns and sat up t...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x35663e</td>\n",
       "      <td>I bet there is an army of married couples who ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>joy</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0xc78afe</td>\n",
       "      <td>This could only end badly.</td>\n",
       "      <td>[]</td>\n",
       "      <td>fear</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x90089c</td>\n",
       "      <td>My sister squeezed a lime in her milk when she...</td>\n",
       "      <td>[]</td>\n",
       "      <td>joy</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0xaba820</td>\n",
       "      <td>and that got my head bobbing a little bit.</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    post_id                                               text hashtags  \\\n",
       "0  0x61fc95  We got the ranch, loaded our guns and sat up t...       []   \n",
       "1  0x35663e  I bet there is an army of married couples who ...       []   \n",
       "2  0xc78afe                         This could only end badly.       []   \n",
       "3  0x90089c  My sister squeezed a lime in her milk when she...       []   \n",
       "4  0xaba820         and that got my head bobbing a little bit.       []   \n",
       "\n",
       "  emotion  split  \n",
       "0     NaN   test  \n",
       "1     joy  train  \n",
       "2    fear  train  \n",
       "3     joy  train  \n",
       "4     NaN   test  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add emotion & train/test set split labels\n",
    "df_tmp = pd.merge(main_df, df_emo, how='left', on='post_id')\n",
    "df = pd.merge(df_tmp, df_split, how='left', on='post_id')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c2e72fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>emotion</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x35663e</td>\n",
       "      <td>I bet there is an army of married couples who ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>joy</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0xc78afe</td>\n",
       "      <td>This could only end badly.</td>\n",
       "      <td>[]</td>\n",
       "      <td>fear</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x90089c</td>\n",
       "      <td>My sister squeezed a lime in her milk when she...</td>\n",
       "      <td>[]</td>\n",
       "      <td>joy</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0x2ffb63</td>\n",
       "      <td>Thank you so much❤️</td>\n",
       "      <td>[]</td>\n",
       "      <td>joy</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0x989146</td>\n",
       "      <td>Stinks because ive been in this program for a ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>joy</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64164</th>\n",
       "      <td>0xd740f2</td>\n",
       "      <td>why is everybody seem sp serious?</td>\n",
       "      <td>[]</td>\n",
       "      <td>joy</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64165</th>\n",
       "      <td>0x99267e</td>\n",
       "      <td>You can cross fuck off, its 10f all winter in ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>anger</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64166</th>\n",
       "      <td>0x4afbe1</td>\n",
       "      <td>Guilty Gear actually did that before with Guil...</td>\n",
       "      <td>[]</td>\n",
       "      <td>anger</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64167</th>\n",
       "      <td>0xf5ba78</td>\n",
       "      <td>One of my favorite episodes.</td>\n",
       "      <td>[]</td>\n",
       "      <td>joy</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64169</th>\n",
       "      <td>0xb5a35a</td>\n",
       "      <td>Texans and Astros both shut out tonight. Houst...</td>\n",
       "      <td>[texans, astros, sadness, losers]</td>\n",
       "      <td>sadness</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47890 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        post_id                                               text  \\\n",
       "1      0x35663e  I bet there is an army of married couples who ...   \n",
       "2      0xc78afe                         This could only end badly.   \n",
       "3      0x90089c  My sister squeezed a lime in her milk when she...   \n",
       "7      0x2ffb63                                Thank you so much❤️   \n",
       "9      0x989146  Stinks because ive been in this program for a ...   \n",
       "...         ...                                                ...   \n",
       "64164  0xd740f2                  why is everybody seem sp serious?   \n",
       "64165  0x99267e  You can cross fuck off, its 10f all winter in ...   \n",
       "64166  0x4afbe1  Guilty Gear actually did that before with Guil...   \n",
       "64167  0xf5ba78                       One of my favorite episodes.   \n",
       "64169  0xb5a35a  Texans and Astros both shut out tonight. Houst...   \n",
       "\n",
       "                                hashtags  emotion  split  \n",
       "1                                     []      joy  train  \n",
       "2                                     []     fear  train  \n",
       "3                                     []      joy  train  \n",
       "7                                     []      joy  train  \n",
       "9                                     []      joy  train  \n",
       "...                                  ...      ...    ...  \n",
       "64164                                 []      joy  train  \n",
       "64165                                 []    anger  train  \n",
       "64166                                 []    anger  train  \n",
       "64167                                 []      joy  train  \n",
       "64169  [texans, astros, sadness, losers]  sadness  train  \n",
       "\n",
       "[47890 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into train and test datasets\n",
    "model_df = df[df['split'] == 'train'].copy()\n",
    "test_df = df[df['split'] == 'test'].copy()\n",
    "\n",
    "print(sum(test_df['emotion'].value_counts()))\n",
    "model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4982fbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "env_path = \"./config/.env\"\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "SYSTEM_PROMPT = (\n",
    "        '''You are a helpful assistant. You give a response by strictly following the instructions, a little creativity is accepted. The task is to generate the previous and the next possible sentence for each Twitter comment in the input list\n",
    "        to extend the contents of the input, combine them with the original comment, and return all of the augmented texts as a list of strings. The contents and the sentiments of both the virtual(generated) texts need to be the same as or similar to \n",
    "        that of the given input. Take special cases, e.g. analogy, metaphor, and sarcasm, into account. The augmented output should be keep as short as possible.'''\n",
    "    )\n",
    "\n",
    "MAX_OUTPUT_TOKENS = 65535\n",
    "MODEL_NAME = 'gemini-2.5-flash'\n",
    "\n",
    "SAFETY_SETTINGS = [\n",
    "    types.SafetySetting(\n",
    "        category=\"HARM_CATEGORY_HATE_SPEECH\", threshold=\"OFF\"),\n",
    "    types.SafetySetting(\n",
    "        category=\"HARM_CATEGORY_DANGEROUS_CONTENT\", threshold=\"OFF\"),\n",
    "    types.SafetySetting(\n",
    "        category=\"HARM_CATEGORY_SEXUALLY_EXPLICIT\", threshold=\"OFF\"),\n",
    "    types.SafetySetting(\n",
    "        category=\"HARM_CATEGORY_HARASSMENT\", threshold=\"OFF\")\n",
    "]\n",
    "\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "os.environ[\"GOOGLE_API_KEY\"] = api_key\n",
    "client = genai.Client(api_key=api_key)\n",
    "\n",
    "if 'GEMINI_API_KEY' not in os.environ:\n",
    "    os.environ['GEMINI_API_KEY'] = api_key\n",
    "\n",
    "schema = types.Schema(\n",
    "     type=types.Type.ARRAY,\n",
    "     items=types.Schema(\n",
    "          type=types.Type.STRING\n",
    "     )\n",
    ")\n",
    "\n",
    "def gemini_api(\n",
    "        input_prompt: list[str],\n",
    "        schema = schema,\n",
    "        temperature: float = 0.2,\n",
    "        system_instruction: str = SYSTEM_PROMPT,\n",
    "        max_output_tokens: int = MAX_OUTPUT_TOKENS,\n",
    "        client: genai.Client = client,\n",
    "        model_name: str = MODEL_NAME,\n",
    "        new_config: types.GenerateContentConfig = None,\n",
    "        with_tools: bool = False,\n",
    "        with_parts: bool = False,\n",
    "        with_tokens_info: bool = False\n",
    "    ):\n",
    "        try:\n",
    "            if schema:\n",
    "                generate_content_config = types.GenerateContentConfig(\n",
    "                    temperature=temperature,\n",
    "                    system_instruction=system_instruction,\n",
    "                    max_output_tokens=max_output_tokens,\n",
    "                    response_modalities=[\"TEXT\"],\n",
    "                    response_mime_type=\"application/json\",\n",
    "                    response_schema=schema,\n",
    "                    safety_settings=SAFETY_SETTINGS\n",
    "                )\n",
    "            else:\n",
    "                generate_content_config = types.GenerateContentConfig(\n",
    "                    temperature=temperature,\n",
    "                    system_instruction=system_instruction,\n",
    "                    max_output_tokens=max_output_tokens,\n",
    "                    response_modalities=[\"TEXT\"],\n",
    "                    safety_settings=SAFETY_SETTINGS\n",
    "                )\n",
    "            \n",
    "            if new_config:\n",
    "                generate_content_config = new_config\n",
    "            \n",
    "            if with_parts:\n",
    "                response = client.models.generate_content(\n",
    "                    model=model_name,\n",
    "                    contents=types.Content(parts=input_prompt),\n",
    "                    config=generate_content_config,\n",
    "                )\n",
    "            else:\n",
    "                response = client.models.generate_content(\n",
    "                    model=model_name,\n",
    "                    contents=input_prompt,\n",
    "                    config=generate_content_config,\n",
    "                )\n",
    "\n",
    "            completion = response.text\n",
    "            if with_tokens_info:\n",
    "                log = {\n",
    "                    \"model\": model_name,\n",
    "                    \"input_tokens\": response.usage_metadata.prompt_token_count,\n",
    "                    \"output_tokens\": response.usage_metadata.candidates_token_count,\n",
    "                }\n",
    "                return completion, log\n",
    "            return completion\n",
    "\n",
    "        except Exception as e:\n",
    "             print(f\"Error occurred when generating response, error: {e}\")\n",
    "             return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9fb6b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import RobertaModel, RobertaTokenizer\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09f0ee4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bi-direction mapping for labels\n",
    "emo_to_int = {'joy': 0, 'surprise': 1, 'anger': 2, 'sadness': 3, 'fear': 4, 'disgust': 5}\n",
    "int_to_emo = {0: 'joy', 1: 'surpirse', 2: 'anger', 3: 'sadness', 4: 'fear', 5:'disgust'}\n",
    "\n",
    "model_df['simple_text'] = model_df['text'].apply(lambda t: emoji.demojize(t))\n",
    "model_df['label'] = model_df['emotion'].apply(lambda x: emo_to_int[x])\n",
    "\n",
    "# Generate virtual augmented text data (failed attempt)\n",
    "# in_prompt = model_df['simple_text'].tolist()\n",
    "# resp = gemini_api(input_prompt=in_prompt)\n",
    "# model_df['augmented_text'] = json.loads(resp)\n",
    "\n",
    "# Train/Test split\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    model_df['simple_text'],\n",
    "    model_df['label'],\n",
    "    test_size=0.3,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "df_train = pd.concat([x_train, y_train], axis=1)\n",
    "df_train.reset_index(inplace=True)\n",
    "df_val = pd.concat([x_val, y_val], axis=1)\n",
    "df_val.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d79fbea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base', cache_dir='./cache/')\n",
    "\n",
    "# Define necessary functions\n",
    "class Dataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = self.texts[index]\n",
    "        label = self.labels[index]\n",
    "\n",
    "        encodes = self.tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=128,\n",
    "            truncation=True,\n",
    "            padding=False,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encodes['input_ids'].flatten(),\n",
    "            'attention_mask': encodes['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "def collate_batch(batch):\n",
    "    input_ids = [data['input_ids'] for data in batch]\n",
    "    attention_masks = [data['attention_mask'] for data in batch]\n",
    "    labels = [data['labels'] for data in batch]\n",
    "\n",
    "    input_id_padded = torch.nn.utils.rnn.pad_sequence(\n",
    "        input_ids, batch_first=True, padding_value=tokenizer.pad_token_id\n",
    "    )\n",
    "    attention_mask_padded = torch.nn.utils.rnn.pad_sequence(\n",
    "        attention_masks, batch_first=True, padding_value=0\n",
    "    )\n",
    "    label_stacked = torch.stack(labels)\n",
    "\n",
    "    return {\n",
    "        'input_ids': input_id_padded,\n",
    "        'attention_mask': attention_mask_padded,\n",
    "        'labels': label_stacked\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7bb3860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 128\n",
    "epochs = 4\n",
    "learning_rate = 2e-5\n",
    "\n",
    "ds_train = Dataset(df_train['simple_text'].tolist(), df_train['label'].tolist(), tokenizer=tokenizer)\n",
    "dl_train = DataLoader(dataset=ds_train, batch_size=batch_size, num_workers=0, collate_fn=collate_batch)\n",
    "ds_val = Dataset(df_val['simple_text'].tolist(), df_val['label'].tolist(), tokenizer=tokenizer)\n",
    "dl_val = DataLoader(dataset=ds_val, batch_size=batch_size, num_workers=0, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5126388",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelRoberta(torch.nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.robert = RobertaModel.from_pretrained('roberta-base')\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Linear(in_features=768, out_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(in_features=128, out_features=6)\n",
    "        )\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        y = self.robert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        y_hidden = y.last_hidden_state[:, 0, :]\n",
    "        logits = self.dense(y_hidden)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e38bbd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "model = ModelRoberta()\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = AdamW(params=model.parameters(), lr=learning_rate, weight_decay=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "932006b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 1: 100%|██████████| 262/262 [05:05<00:00,  1.17s/it, loss=0.796]\n",
      "Validation phase: 100%|██████████| 113/113 [00:53<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score (Epoch 1):\n",
      "0.6578333269356351\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 2: 100%|██████████| 262/262 [05:20<00:00,  1.22s/it, loss=0.746]\n",
      "Validation phase: 100%|██████████| 113/113 [00:58<00:00,  1.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score (Epoch 2):\n",
      "0.6768496085318025\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 3: 100%|██████████| 262/262 [03:47<00:00,  1.15it/s, loss=0.761]\n",
      "Validation phase: 100%|██████████| 113/113 [01:13<00:00,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score (Epoch 3):\n",
      "0.6808820402205179\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Start training\n",
    "i = 0\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    progress = tqdm(dl_train, desc=f\"Training epoch {epoch+1}\")\n",
    "\n",
    "    for batch in progress:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        # Get model output\n",
    "        output_y = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = criterion(output_y, labels)\n",
    "\n",
    "        # Update\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        i += 1\n",
    "        if i % 50 == 0:\n",
    "            progress.set_postfix({'loss': f\"{loss.item(): .3f}\"})\n",
    "\n",
    "    model.eval()\n",
    "    PRED_LABEL = list()\n",
    "    TRUE_LABEL = list()\n",
    "    evaluation = tqdm(dl_val, desc=f\"Validation phase\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in evaluation:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            pred_y = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            pred_labels = torch.argmax(pred_y, dim=1)\n",
    "            TRUE_LABEL.extend(labels.cpu().numpy())\n",
    "            PRED_LABEL.extend(pred_labels.detach().cpu().numpy())\n",
    "\n",
    "        f1 = f1_score(TRUE_LABEL, PRED_LABEL, average='weighted')\n",
    "        print(f\"F1-Score (Epoch {epoch+1}):\\n{f1}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2336d79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction for test data\n",
    "test_df['simple_text'] = test_df['text'].apply(lambda t: emoji.demojize(t))\n",
    "test_raw = test_df['simple_text'].tolist()\n",
    "final_preds = list()\n",
    "test_batch = 32\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i in range(int(math.ceil(len(test_raw)/test_batch))):\n",
    "        start_bacth = i * test_batch\n",
    "        end_bacth = (i + 1) * test_batch\n",
    "        x_test = tokenizer(\n",
    "            test_raw[start_bacth:end_bacth],\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=128,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        x_ids = x_test['input_ids'].to(device)\n",
    "        x_masks = x_test['attention_mask'].to(device)\n",
    "        y_test = model(input_ids=x_ids, attention_mask=x_masks)\n",
    "        pred_test = torch.argmax(y_test, dim=1)\n",
    "        final_preds.extend(pred_test.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b54ba230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x61fc95</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0xaba820</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0x66e44d</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0xc03cf5</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0x02f65a</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64146</th>\n",
       "      <td>0x0f273c</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64150</th>\n",
       "      <td>0xfc4c5d</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64157</th>\n",
       "      <td>0xb318a3</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64168</th>\n",
       "      <td>0x8f758e</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64170</th>\n",
       "      <td>0x3a9174</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16281 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  emotion\n",
       "0      0x61fc95     fear\n",
       "4      0xaba820     fear\n",
       "5      0x66e44d      joy\n",
       "6      0xc03cf5      joy\n",
       "8      0x02f65a    anger\n",
       "...         ...      ...\n",
       "64146  0x0f273c      joy\n",
       "64150  0xfc4c5d  sadness\n",
       "64157  0xb318a3  sadness\n",
       "64168  0x8f758e     fear\n",
       "64170  0x3a9174      joy\n",
       "\n",
       "[16281 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['label'] = np.array(final_preds)\n",
    "test_df['emotion'] = test_df['label'].apply(lambda x: int_to_emo[x])\n",
    "test_df.rename(columns={'post_id': 'id'}, inplace=True)\n",
    "\n",
    "final_df = test_df[['id', 'emotion']]\n",
    "final_df.to_csv('./data/result.csv', index=False)\n",
    "final_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dm2025lab)",
   "language": "python",
   "name": "dm2025lab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
